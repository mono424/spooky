import { spawn, execSync } from "child_process";
import { fileURLToPath } from "url";
import { dirname, join } from "path";
import { readFileSync, writeFileSync, unlinkSync } from "fs";
import { tmpdir } from "os";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

export interface SyncgenOptions {
  input: string;
  output: string;
  format?: "json" | "typescript" | "dart" | "surql";
  pretty?: boolean;
  all?: boolean;
  noHeader?: boolean;
  append?: string;
}

export function runSyncgen(options: SyncgenOptions): Promise<string> {
  return new Promise((resolve, reject) => {
    const binaryPath = join(__dirname, "..", "target", "release", "syncgen");

    let inputPath = options.input;
    let tempFilePath: string | null = null;

    let finalContent = "";
    try {
      finalContent = readFileSync(options.input, "utf-8");
    } catch (err) {
      return reject(err);
    }

    if (options.append) {
      try {
        const appendContent = readFileSync(options.append, "utf-8");
        finalContent = finalContent + "\n\n" + appendContent;
      } catch (err) {
        return reject(err);
      }
    }

    // Check if output is .surql or format is surql
    const isSurqlOutput = options.output.endsWith(".surql") || options.format === "surql";

    // Generate Spooky Events
    try {
      if (isSurqlOutput) {
        const events = generateSpookyEvents(options.input, binaryPath);
        finalContent += "\n\n" + events;
      }
    } catch (err) {
      console.warn("Failed to generate Spooky Events:", err);
    }

    if (isSurqlOutput) {
      try {
        const header = "-- This file is auto-generated. Do not edit manually.\n-- Generated by syncgen - any changes will be overwritten.\n\n";
        writeFileSync(options.output, header + finalContent, "utf-8");
        return resolve(`Successfully generated SQL at "${options.output}"`);
      } catch (err) {
        return reject(err);
      }
    }

    if (options.append) {
      try {
        const timestamp = Date.now();
        const rand = Math.floor(Math.random() * 10000);
        tempFilePath = join(tmpdir(), `syncgen-schema-${timestamp}-${rand}.surql`);
        
        writeFileSync(tempFilePath, finalContent, "utf-8");
        inputPath = tempFilePath;
      } catch (err) {
        return reject(err);
      }
    }

    const args = ["--input", inputPath, "--output", options.output];

    if (options.format) {
      args.push("--format", options.format);
    }

    if (options.pretty === true) {
      args.push("--pretty");
    }

    if (options.all === true) {
      args.push("--all");
    }

    if (options.noHeader === true) {
      args.push("--no-header");
    }

    const child = spawn(binaryPath, args);

    let stdout = "";
    let stderr = "";

    child.stdout.on("data", (data) => {
      stdout += data.toString();
    });

    child.stderr.on("data", (data) => {
      stderr += data.toString();
    });

    child.on("close", (code) => {
      if (tempFilePath) {
        try {
          unlinkSync(tempFilePath);
        } catch (e) {
          // Ignore error on cleanup
        }
      }

      if (code === 0) {
        resolve(stdout);
      } else {
        reject(new Error(`syncgen exited with code ${code}: ${stderr}`));
      }
    });

    child.on("error", (error) => {
      if (tempFilePath) {
        try {
          unlinkSync(tempFilePath);
        } catch (e) {
          // Ignore error on cleanup
        }
      }
      reject(error);
    });
  });
}

function generateSpookyEvents(schemaPath: string, binaryPath: string): string {
  // 1. Get JSON Schema from syncgen binary
  const timestamp = Date.now();
  const rand = Math.floor(Math.random() * 10000);
  const tempJsonPath = join(tmpdir(), `syncgen-schema-${timestamp}-${rand}.json`);

  try {
    execSync(`"${binaryPath}" --input "${schemaPath}" --output "${tempJsonPath}" --format json`);
    const jsonContent = readFileSync(tempJsonPath, "utf-8");
    const schema = JSON.parse(jsonContent);
    unlinkSync(tempJsonPath);

    // 2. Parse schema.surql to find @parent annotations
    const schemaContent = readFileSync(schemaPath, "utf-8");
    const parentMap: Record<string, string> = {}; // childTable -> parentField
    
    const lines = schemaContent.split("\n");
    for (const line of lines) {
      const match = line.match(/DEFINE\s+FIELD\s+(\w+)\s+ON\s+TABLE\s+(\w+).*--\s*@parent/i);
      if (match) {
        const [, field, table] = match;
        parentMap[table.toLowerCase()] = field.toLowerCase();
      }
    }

    // 3. Generate Events
    let events = "-- ==================================================\n-- AUTO-GENERATED SPOOKY EVENTS\n-- ==================================================\n\n";

    const definitions = schema.definitions || {};

    // Filter out Relation tables and definitions that are not tables
    const tableNames = Object.keys(definitions).filter(name => {
      const def = definitions[name];
      return name !== "Relationships" && 
             name !== "RelationTables" && 
             !def["x-is-relation-table"] && 
             def.properties && 
             !def.properties["x-is-reverse-relationship"]; 
    });

    for (const tableName of tableNames) {
      if (tableName.startsWith("_spooky_")) continue; // Matches new prefix

      const def = definitions[tableName];
      const properties = def.properties || {};
      
      const parentField = parentMap[tableName];
      
      // Calculate Intrinsic Fields
      const intrinsicFields: string[] = [];

      for (const [propName, propDef] of Object.entries(properties)) {
        const prop = propDef as any;
        if (prop["x-is-reverse-relationship"]) continue;
        
        // Add to intrinsic hash
        intrinsicFields.push(`${propName}: $after.${propName}`);
      }

      // --------------------------------------------------
      // A. Mutation Event
      // --------------------------------------------------
      events += `-- Table: ${tableName} Mutation\n`;
      events += `DEFINE EVENT OVERWRITE _spooky_${tableName}_mutation ON TABLE ${tableName}\n`;
      events += `WHEN $before != $after\nTHEN {\n`;
      
      // 1. New Intrinsic Hash
      events += `    LET $new_intrinsic = crypto::blake3({\n`;
      events += `        ${intrinsicFields.join(",\n        ")}\n`;
      events += `    });\n\n`;

      // 2. Previous Hash State
      events += `    LET $old_hash_data = (SELECT * FROM ONLY _spooky_data_hash WHERE RecordId = $before.id);\n`;
      events += `    LET $old_total = $old_hash_data.TotalHash OR <bytes>[];\n`;
      events += `    LET $composition = $old_hash_data.CompositionHash OR <bytes>[];\n\n`;

      // 3. New Total Hash
      events += `    LET $new_total = array::boolean_xor($new_intrinsic, $composition);\n\n`;

      // 4. Upsert Meta Table
      events += `    UPSERT _spooky_data_hash CONTENT {\n`;
      events += `        RecordId: $after.id,\n`;
      events += `        IntrinsicHash: $new_intrinsic,\n`;
      events += `        CompositionHash: $composition,\n`;
      events += `        TotalHash: $new_total\n`;
      events += `    };\n\n`;

      // 5. Bubble Up (If Parent exists)
      if (parentField) {
        events += `    -- BUBBLE UP to Parent (${parentField})\n`;
        events += `    IF $before.${parentField} = $after.${parentField} THEN {\n`;
        events += `        LET $delta = array::boolean_xor($old_total, $new_total);\n`;
        events += `        UPDATE _spooky_data_hash SET\n`;
        events += `            CompositionHash = array::boolean_xor(CompositionHash, $delta),\n`;
        events += `            TotalHash = array::boolean_xor(IntrinsicHash, array::boolean_xor(CompositionHash, $delta))\n`;
        events += `        WHERE RecordId = $after.${parentField};\n`;
        events += `    } ELSE {\n`;
        // Remove contribution from Old Parent
        events += `        UPDATE _spooky_data_hash SET\n`;
        events += `            CompositionHash = array::boolean_xor(CompositionHash, $old_total),\n`;
        events += `            TotalHash = array::boolean_xor(IntrinsicHash, array::boolean_xor(CompositionHash, $old_total))\n`;
        events += `        WHERE RecordId = $before.${parentField} AND RecordId != NONE;\n`;

        // Add contribution to New Parent
        events += `        UPDATE _spooky_data_hash SET\n`;
        events += `            CompositionHash = array::boolean_xor(CompositionHash, $new_total),\n`;
        events += `            TotalHash = array::boolean_xor(IntrinsicHash, array::boolean_xor(CompositionHash, $new_total))\n`;
        events += `        WHERE RecordId = $after.${parentField} AND RecordId != NONE;\n`;
        events += `    } END;\n\n`;
      }

      // 6. Cascade Down (Incoming References)
      // Check which other tables reference us
      let cascadeUpdates = "";
      
      for (const otherTable of tableNames) {
          if (otherTable === tableName) continue;
          const otherDef = definitions[otherTable];
          const otherProps = otherDef.properties || {};
          
          for (const [otherPropName, otherPropDef] of Object.entries(otherProps)) {
              const prop = otherPropDef as any;
              if (prop["x-is-reverse-relationship"]) continue;
              
              if (prop.pattern && prop.pattern instanceof String && prop.pattern.startsWith("^")) {
                  const targetTable = prop.pattern.substring(1, prop.pattern.length - 1);
                  if (targetTable === tableName) {
                      // Check if this is NOT a parent relationship
                      const isParentField = parentMap[otherTable] === otherPropName;
                      if (!isParentField) {
                          cascadeUpdates += `        UPDATE ${otherTable} SET _spooky_dirty = time::now() WHERE ${otherPropName} = $after.id;\n`;
                      }
                  }
              } else if (prop.type === "string" && prop.description && prop.description.startsWith("Record ID of table:")) {
                  // Fallback for cases where pattern might be different or parsed differently
                  const targetTable = prop.description.replace("Record ID of table: ", "");
                  if (targetTable === tableName) {
                      const isParentField = parentMap[otherTable] === otherPropName;
                      if (!isParentField) {
                             cascadeUpdates += `        UPDATE ${otherTable} SET _spooky_dirty = time::now() WHERE ${otherPropName} = $after.id;\n`;
                      }
                  }
              }
          }
      }

      if (cascadeUpdates.length > 0) {
          events += `    -- CASCADE DOWN (References)\n`;
          events += `    IF $old_hash_data.RecordId != NONE AND $new_intrinsic != $old_hash_data.IntrinsicHash THEN {\n`;
          events += cascadeUpdates;
          events += `    } END;\n`;
      }

      events += `};\n\n`;

      // --------------------------------------------------
      // B. Deletion Event
      // --------------------------------------------------
      events += `-- Table: ${tableName} Deletion\n`;
      events += `DEFINE EVENT OVERWRITE _spooky_${tableName}_delete ON TABLE ${tableName}\n`;
      events += `WHEN $event = "DELETE"\nTHEN {\n`;
      events += `    LET $old_hash_data = (SELECT * FROM ONLY _spooky_data_hash WHERE RecordId = $before.id);\n`;
      events += `    LET $old_total = $old_hash_data.TotalHash;\n\n`;

      if (parentField) {
        events += `    -- BUBBLE UP Delete to Parent\n`;
        events += `    IF $old_total != NONE AND $before.${parentField} != NONE THEN {\n`;
        events += `        UPDATE _spooky_data_hash SET\n`;
        events += `            CompositionHash = array::boolean_xor(CompositionHash, $old_total),\n`;
        events += `            TotalHash = array::boolean_xor(IntrinsicHash, array::boolean_xor(CompositionHash, $old_total))\n`;
        events += `        WHERE RecordId = $before.${parentField};\n`;
        events += `    } END;\n\n`;
      }
      
      events += `    DELETE _spooky_data_hash WHERE RecordId = $before.id;\n`;
      events += `};\n\n`;
    }

    return events;
  } catch (err) {
    if (tempJsonPath) try { unlinkSync(tempJsonPath); } catch (e) {}
    throw err;
  }
}
